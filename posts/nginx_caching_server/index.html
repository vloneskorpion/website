<!doctype html><html lang=en-us dir=ltr><head><meta charset=UTF-8><meta name=viewport content="width=device-width,initial-scale=1"><title>How to use nginx as caching server? - knowak.dev</title>
<meta name=description content="A DevOps, Linux, and Programming Journal"><link rel=preconnect href=https://fonts.googleapis.com><link rel=preconnect href=https://fonts.gstatic.com crossorigin><link href="https://fonts.googleapis.com/css2?family=Roboto+Mono:wght@400;500;700&display=swap" rel=stylesheet><link rel=stylesheet href=https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css><link rel=stylesheet href=/css/bundle.min.441e898271d60980fe7c49a2d2b9c334024c6cf4fd06d9cce5ffb7663d08924ac948ef2dca1e42fb2110f4d5a9122c0e3e6b6fa446f28792e04a9b6bc147e26d.css integrity="sha512-RB6JgnHWCYD+fEmi0rnDNAJMbPT9BtnM5f+3Zj0IkkrJSO8tyh5C+yEQ9NWpEiwOPmtvpEbyh5LgSptrwUfibQ=="><link rel=stylesheet href=/css/emergency-list-fix.css><link rel=icon type=image/png href=/images/favicon.png><style>.post{background:var(--card-background);border:1px solid var(--card-border);border-radius:5px;margin-bottom:2rem;padding:2rem}.post-header{margin-bottom:2rem;text-align:center}.post-title{color:var(--neon-cyan);font-size:2.5rem;margin:0 0 1rem}.post-content{font-size:1.1rem;line-height:1.8}.post-content img{border:1px solid var(--neon-cyan);border-radius:5px;display:block;max-width:100%;margin:2rem auto}.post-navigation{display:flex;justify-content:space-between;margin-top:3rem}.prev-post,.next-post{background:var(--card-background);border:1px solid var(--card-border);border-radius:3px;color:var(--light-text);display:inline-block;max-width:45%;padding:.5rem 1rem;text-decoration:none;transition:border-color .3s ease,box-shadow .3s ease;white-space:nowrap;overflow:hidden;text-overflow:ellipsis}.prev-post:hover,.next-post:hover{border-color:var(--neon-cyan);box-shadow:0 0 10px rgba(14,255,255,.3)}#TableOfContents{font-size:.9rem}#TableOfContents ul{list-style-type:none;padding-left:1rem}#TableOfContents>ul{padding-left:0}#TableOfContents a{color:var(--neon-cyan);display:inline-block;margin:.25rem 0;text-decoration:none;transition:color .3s ease}#TableOfContents a:hover{color:var(--neon-pink)}.highlight{border-radius:5px;margin:1.5rem 0;position:relative}</style></head><body><div class=container><header><h1 class=site-title><a href=/>knowak.dev</a></h1><p class=site-description>A DevOps, Linux, and Programming Journal</p><nav><ul><li><a href=/>Home</a></li><li><a href=/tags/>Tags</a></li><li><a href=/about/>About</a></li><li><a href=/archive/>Archive</a></li></ul></nav></header><main><article class=post><header class=post-header><h1 class=post-title>How to use nginx as caching server?</h1><div class=post-meta><span><i class="far fa-calendar-alt"></i> January 11, 2025</span>
<span><i class="far fa-clock"></i> 4 min read</span></div></header><div class=post-content><p>In this tutorial, we’ll explore the caching functionality of nginx by creating a simple caching server. By following the steps below, you can set up your own environment to cache responses using nginx.</p><p>For those who don&rsquo;t know what nginx is - a high-performance, open-source web server that’s also frequently used as a reverse proxy, load balancer, and content cache. It was designed to handle large numbers of concurrent connections efficiently, often making it a go-to choice for high-traffic websites.</p><p>First, install nginx if you haven’t already:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo apt install nginx
</span></span></code></pre></div><p>Then enable and start it via systemd:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl enable --now nginx
</span></span></code></pre></div><p>Next, create a dedicated directory for caching and secure it:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo mkdir -p /var/cache/nginx
</span></span><span style=display:flex><span>sudo chmod <span style=color:#ae81ff>700</span> /var/cache/nginx
</span></span></code></pre></div><p>Open the main nginx configuration file <code>/etc/nginx/nginx.conf</code> in your favourite editor. Replace the existing http { &mldr; } block with the following:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>http <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>    proxy_cache_path /var/cache/nginx levels<span style=color:#f92672>=</span>1:2 keys_zone<span style=color:#f92672>=</span>my_cache:10m max_size<span style=color:#f92672>=</span>10g inactive<span style=color:#f92672>=</span>60m use_temp_path<span style=color:#f92672>=</span>off;
</span></span><span style=display:flex><span>	
</span></span><span style=display:flex><span>    server <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>        listen 80;
</span></span><span style=display:flex><span>        server_name caching_server;
</span></span><span style=display:flex><span>        location / <span style=color:#f92672>{</span>
</span></span><span style=display:flex><span>            proxy_pass http://127.0.0.1:1234;
</span></span><span style=display:flex><span>            proxy_cache my_cache;
</span></span><span style=display:flex><span>            proxy_cache_valid <span style=color:#ae81ff>200</span> 1h;
</span></span><span style=display:flex><span>            proxy_cache_valid <span style=color:#ae81ff>404</span> 30m;
</span></span><span style=display:flex><span>            proxy_cache_use_stale error timeout invalid_header updating;
</span></span><span style=display:flex><span>            add_header X-Cache-Status $upstream_cache_status;
</span></span><span style=display:flex><span>        <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span>    <span style=color:#f92672>}</span>
</span></span><span style=display:flex><span><span style=color:#f92672>}</span>
</span></span></code></pre></div><p>It seems to be a lot of lines, but actually it&rsquo;s not complicated at all. Here is detailed description of what each option does:</p><ul><li><code>proxy_cache_path</code><ul><li><code>/var/cache/nginx</code> - specifies the dir where cached files will be stored</li><li><code>levels=1:2</code> - defines the dir structure for the cache, <code>1:2</code> means that the cache will have two levels of subdirectories, thats how it will look like after cache will be created:</li></ul></li></ul><p><img src=/images/nginx_caching_server/20250110183455.png alt="Nginx cache directory structure"></p><ul><li><code>keys_zone=my_cache:10m</code> - allocates a shared memory zone with name <code>my_cache</code> and <code>10 MB</code> of storage for cache metadata. This memory is used for fast lookup for cached responses.<ul><li><code>max_size=10g</code> - limits the total size of the cache to 10 GB, when it reaches the limit old files are removed</li><li><code>inactive=60m</code> - specifies that the cached items will be removed if not accesses within 60 mins</li><li><code>use_temp_path=off</code> - ensures cached files are written directly to the cache directory instead of temporary directory</li></ul></li><li><code>server</code> block defines settings for the virtual server<ul><li><code>listen 80</code> - specifies port to listen on</li><li><code>server_name caching_server</code> - specifies the server name</li><li><code>location /</code> - specifies settings for specific URL path in this case <code>/</code><ul><li><code>proxy_pass http://127.0.0.1:1234</code> - directs requests to the backend server at provided path, in this example we will direct requests to <code>localhost</code> on post <code>1234</code></li><li><code>proxy_cache my_cache</code> - enables caching for this location using the cache defined in <code>my_cache</code></li><li><code>proxy_cache_valid 200 1h</code> - specifies that responses with return status 200 (OK) will be cached for 1h</li><li><code>proxy_cache_valid 404 30m</code> - specifies that responses with return status 404 (Not Found) will be cached for 30 mins</li><li><code>proxy_cache_use_stale error timeout invalid_header updating</code> - allows serving cached content in specific scenarios related to backend server: <code>error</code> - server unavailable, <code>timeout</code> - server takes too much time to respond, <code>invalid_header</code> - response from backend is invalid, <code>updating</code> - when a fresh version of the cache is being updated</li><li><code>add_header X-Cache-Status $upstream_cache_status</code> - adds custom header to responses for reporting cache status: <code>MISS</code> - response not found in cache, <code>HIT</code> - response found in cache, <code>EXPIRED</code> - cached response expired and a new one was fetched</li></ul></li></ul></li></ul><p>If you don&rsquo;t want to change <code>server_name caching_server</code> in your configuration to your own one, make sure that your system can resolve the hostname caching_server. One way to do this is by adding an entry to your <code>/etc/hosts</code> file:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>echo <span style=color:#e6db74>&#34;127.0.0.1  caching_server&#34;</span> | sudo tee -a /etc/hosts
</span></span></code></pre></div><p>Check if syntax of edited config file is correct via:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>nginx -t
</span></span></code></pre></div><p>If everything is ok, then reload nginx using systemctl so changes will be applied:</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>sudo systemctl reload nginx
</span></span></code></pre></div><p>Now, when you know what each option does we can proceed to test new configuration. Let&rsquo;s create simple server using <code>netcat</code> in while loop which will give a simple response each time we access <code>localhost</code> at port <code>1234</code>.</p><div class=highlight><pre tabindex=0 style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span><span style=color:#66d9ef>while</span> true; <span style=color:#66d9ef>do</span>
</span></span><span style=display:flex><span>    echo -e <span style=color:#e6db74>&#34;HTTP/1.1 200 OK\r\nContent-Type: text/plain\r\nContent-Length: 13\r\n\r\nHello, world!&#34;</span> | nc -l -p 1234;
</span></span><span style=display:flex><span><span style=color:#66d9ef>done</span>
</span></span></code></pre></div><p>Now from other terminal session we can <code>curl</code> our backend server and see if caching utility works:</p><p><img src=/images/nginx_caching_server/20250110183735.png alt="First request to nginx cache"></p><p>The first request should return an X-Cache-Status: MISS, meaning it wasn’t in the cache initially. Subsequent requests should return X-Cache-Status: HIT, indicating the response has been cached.</p><p><img src=/images/nginx_caching_server/20250110183830.png alt="Subsequent request to nginx cache"></p><p>It works, let&rsquo;s check contents of <code>/var/cache/nginx</code> directory.</p><p><img src=/images/nginx_caching_server/20250110183455.png alt="Nginx cache directory structure"></p><p>As you can see our cache exists in disk memory.</p><p>That’s it! By following these steps, you’ve set up a simple nginx caching server and learned how to inspect whether responses are coming from cache. You can adapt these settings to fit your production environment or further explore advanced caching features like cache purging or conditional caching.</p></div><div class=post-tags><a href=/tags/devops class=tag>devops</a>
<a href=/tags/linux class=tag>linux</a>
<a href=/tags/nginx class=tag>nginx</a>
<a href=/tags/caching_server class=tag>caching_server</a></div><div class=post-navigation><a href=/posts/lxc_containers_access_from_lan/ class=prev-post><i class="fas fa-chevron-left"></i> How to access LXC container from LAN?</a></div></article></main><footer><div class=social-links><a href=https://github.com/vloneskorpion class=social-link target=_blank rel="noopener noreferrer"><i class="fab fa-github"></i>
</a><a href=https://www.linkedin.com/in/kamilnowak432 class=social-link target=_blank rel="noopener noreferrer"><i class="fab fa-linkedin"></i></a></div><p class=copyright>© 2025 knowak.dev</p></footer></div><script src=/js/main.min.34d8dddb9e55be0a91d431e37847b8f08f179e8c132b106481efeb0337bd55ead688e9e7559444f1c7e5db67682e335d1ac7316e12538663159f704b068cecdf.js integrity="sha512-NNjd255VvgqR1DHjeEe48I8XnowTKxBkge/rAze9VerWiOnnVZRE8cfl22doLjNdGscxbhJThmMVn3BLBozs3w=="></script></body></html>